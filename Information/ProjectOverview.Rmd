---
title: "Data science coursera track final project"
author: "Joris Van den Bossche"
date: "26 september 2016"
output: 
  html_document:
    keep_md: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(cache = FALSE)
knitr::opts_knit$set(root.dir = normalizePath('../'))
```

# Global options
global options and the libraries used are found in the Global folder:
```{r}
source("00_Global/libraries.R")
source("00_Global/settings.R")
```


# Reading in data
Functions are defined in this folder for downloading, sampling and loading the data into R.
```{r sourceLoad, cache = FALSE}
source("01_Load/load.R")
```

## Usage
Downloading the data:
```{r downloadFiles}
if(!file.exists("RawData/final")){
  downloadFiles()
}
```

To load a sample of the files into R, function "readTextsSample" was created:
```{r readSample}
readTextsSample(lines = 2, lang = "en_US")
twitterTexts
```

Creating a subfolder "sample" in the "RawData" folder. This may take a few minutes.
```{r createSample, eval = FALSE}
createSampleDataDir(usePercentageOfData, seed, lang = "en_US")
```

Reading the sample data into a corpus is done using function "createCorpus":
```{r createCorpus, cache = TRUE, results = 'hide'}
corpus <- createCorpus(lang = "en_US")
tdm <- TermDocumentMatrix(corpus, control = list(wordLengths=c(0, Inf)))
```

# Exploratory Analysis
```{r sourceExplAnalysis}
source("02_ExploratoryAnalysis/Explore.R")
```

Constructing a word freqency table from a term document matrix:
```{r wordFreq}
wordFreqTable <- wordFreq(tdm)
wordFreqTable[1:10, ] # The 10 most frequent words
wordFreqTable # The 10 most frequent words
```

Most words only appear once. The frequency is distributed as such:
```{r wordDensity}
density <- wordFreqTable[, .(count = .N), by = freq]
density[, density := count /sum(density$count)]
density[order(-density)][1:10] # The 10 most frequent word frequencies
```

Creating the table of n-grams of length 2:
```{r ngram2}
n2grams <- ngramsFromCorpus(corpus, n = 2)
n2gramsTable <- data.table(get.phrasetable(n2grams))
n2gramsTable[, density := freq / sum(n2gramsTable$freq)]
n2gramsTable[order(-density)][1:10] # The 10 most frequent 2-grams
```

A histogram of the freqency of the ngrams of length 2:
```{r ngram2hist}
ggplot(data= n2gramsTable) + 
  geom_freqpoly(aes(freq))
```
```{r}

```

As expected, most n-grams are quite rare. The same for the n-grams of length 3:
```{r ngram3}
n3grams <- ngramsFromCorpus(corpus, n = 3)
n3gramsTable <- data.table(get.phrasetable(n3grams))
n3gramsTable[, density := freq / sum(n3gramsTable$freq)]
n3gramsTable[order(-density)][1:10] # The 10 most frequent 3-grams
```

A histogram of the freqency of the ngrams of length 3:
```{r ngram3hist}
ggplot(data= n3gramsTable) + 
  geom_freqpoly(aes(freq))
```

# Modelling
```{r modelling}
source("03_Modelling/Models.R")
```

This first model looks at the freqency table of the 3-grams and takes the three options that are most frequent. If less than three options are found, it will look at the 2-grams table. If still no options are found, it will look at the most freqent words.
```{r model1Examples}
freqModel <- createFreqModel(corpus, tdm)
print(predict(freqModel, "then", "you"))
print(predict(freqModel, "sometimes", "you"))
print(predict(freqModel, "xnjiqqfqsf", "you"))
print(predict(freqModel, "xnjiqqfqsf", "nqnjndjiqpdns"))
```

To save space, the words will be stored as numbers, according to their rank in the freqency table
```{r showModel}
freqModel
```

The size of the model:
```{r}
object.size(freqModel)
object.size(freqModel)*10^-6 # In megabytes
```

Evaluation of the model is done by this function. When a sample was taken of the data set for training the model, there was also a map made with testing data.
```{r testModel1}
source("03_Modelling/Evaluation.R")
testModel(freqModel, fraction = 0.1)
```

The prediction succes can be higher by letting the prediction model give more options. If we change the model to give 5 possibilities instead of only 3, the succesrate goes up:
```{r testModel2}
source("03_Modelling/Evaluation.R")
giveNumberOfPossibilities <- 5
testModel(freqModel, fraction = 0.1)
```