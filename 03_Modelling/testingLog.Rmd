---
title: "TestingLog"
author: "Joris Van den Bossche"
date: "28 november 2016"
output: html_document
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

# Setup
All tests are based on a model based on 0.5% of the total data set:

# Initial testing
```{r}
testModel(freqModel, fraction = 0.01)
```

[[1]]
                  Words total Prediction success % successful prediction
en_US.blogs.txt          1945                571               0.2935733
en_US.news.txt            188                 49               0.2606383
en_US.twitter.txt        1982                663               0.3345106
Total                    4115               1283               0.3117861

[[2]]
      word1      word2      word3      word4      word5
1 0.1657351 0.06123937 0.03863913 0.02332928 0.02284326

```{r}
object.size(freqModel)
```
13118160 bytes

# Removing the n-grams with frequency 1 in the model
```{r}
testModel(freqModel, fraction = 0.01)
```

[[1]]
                  Words total Prediction success % successful prediction
en_US.blogs.txt          1945                589               0.3028278
en_US.news.txt            188                 47               0.2500000
en_US.twitter.txt        1982                656               0.3309788
Total                    4115               1292               0.3139733

[[2]]
      word1      word2      word3      word4      word5
1 0.1681652 0.06439854 0.03912515 0.02527339 0.01701094

Conclusions: A slight improvement, but best of all the model has been cut drastically:
```{r}
testModel(freqModel, fraction = 0.01)
```
3170264 bytes

# Freqency test: How low can we go?
Testing cutoff freqency at 2:
Prediction success: 0.3061968
Object size: 2435424 bytes

Testing cutoff freqency at 5:
Prediction success: 0.2838396
Object size: 1997776 bytes

Testing cutoff freqency at 10:
Prediction success: 0.2712029
Object size: 1861440 bytes

Conclusion: Seems dropping only the ones with freqency 1 yields the best results.

# 